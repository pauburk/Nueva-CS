{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree with the Iris Dataset\n",
    "\n",
    "For an explanation of decision trees, see [our course notes](https://jennselby.github.io/MachineLearningCourseNotes/#decision-trees).\n",
    "\n",
    "This notebook uses example code from http://scikit-learn.org/stable/modules/tree.html.\n",
    "\n",
    "## Instructions\n",
    "0. If you haven't already, follow [the setup instructions here](https://jennselby.github.io/MachineLearningCourseNotes/#setting-up-python3) to get all necessary software installed.\n",
    "0. Install the software specific to this notebook, as explained in the [Setup](#Setup) section.\n",
    "0. Read through the code in the following sections:\n",
    "    * [Iris Dataset](#Iris-Dataset)\n",
    "    * [Visualization of Dataset](#Visualization-of-Dataset)\n",
    "    * [Model Training](#Model-Training)\n",
    "    * [Visualization of Model Output](#Visualization-of-Model-Output)\n",
    "    * [Prediction](#Prediction)\n",
    "0. Complete one or both exercise options:\n",
    "    * [Exercise Option #1 - Standard Difficulty](#Exercise-Option-#1---Standard-Difficulty)\n",
    "    * [Exercise Option #2 - Advanced Difficulty](#Exercise-Option-#2---Advanced-Difficulty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before you can run this code, you will need to install some extra software.\n",
    "\n",
    "1. Install homebrew (if you don't already have it) following the [directions on their site](https://brew.sh/).\n",
    "1. Install the graphviz library that will let us visualize the decision tree. In Terminal, run\n",
    ">`brew install graphviz`\n",
    "1. Install the pydot library that allows you to call graphviz from Python. In Terminal run\n",
    ">`pip3 install pydot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris # the iris dataset is included in scikit-learn https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n",
    "from sklearn import tree # for fitting our model\n",
    "\n",
    "# these are all needed for the particular visualization we're doing\n",
    "from six import StringIO\n",
    "import pydot\n",
    "import os.path\n",
    "\n",
    "# to display graphs in this notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset\n",
    "\n",
    "Before you go on, make sure you understand this dataset. Modify the cell below to examine different parts of the dataset that are contained in the 'iris' dictionary object.\n",
    "\n",
    "**What are the features? What are we trying to classify?**\n",
    "\n",
    "The features are sepal length, sepal width, petal length, and petal width (all in cm). We are trying to classify irises (flowers) based off of those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "print(iris.target_names)\n",
    "print(iris.feature_names)\n",
    "print(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try looking at it using a [pandas dataframe](https://jennselby.github.io/MachineLearningCourseNotes/#pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0  setosa  \n",
       "1  setosa  \n",
       "2  setosa  \n",
       "3  setosa  \n",
       "4  setosa  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "iris_df = pandas.DataFrame(iris.data)\n",
    "iris_df.columns = iris.feature_names\n",
    "iris_df['target'] = [iris.target_names[target] for target in iris.target]\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)  \n",
       "count        150.000000  \n",
       "mean           1.199333  \n",
       "std            0.762238  \n",
       "min            0.100000  \n",
       "25%            0.300000  \n",
       "50%            1.300000  \n",
       "75%            1.800000  \n",
       "max            2.500000  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.describe() # gets statistics about the df (min, max, stdev, mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Dataset\n",
    "\n",
    "Let's visualize our dataset, so that we can better understand what it looks like.\n",
    "\n",
    "Change the first two variables to change which features you are looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot two of the features (the first and fourth columns, in this case)\n",
    "x1_feature = 0\n",
    "x2_feature = 3\n",
    "\n",
    "x1 = iris.data[:,x1_feature]\n",
    "x2 = iris.data[:,x2_feature]\n",
    "\n",
    "# The data are in order by type. Find out where the other types start\n",
    "start_type_one = list(iris.target).index(1)\n",
    "start_type_two = list(iris.target).index(2)\n",
    "\n",
    "# create a figure and label it\n",
    "fig = matplotlib.pyplot.figure()\n",
    "fig.suptitle('Two Features of the Iris Data Set')\n",
    "matplotlib.pyplot.xlabel(iris.feature_names[x1_feature])\n",
    "matplotlib.pyplot.ylabel(iris.feature_names[x2_feature])\n",
    "\n",
    "# put the input data on the graph, with different colors and shapes for each type\n",
    "scatter_0 = matplotlib.pyplot.scatter(x1[:start_type_one], x2[:start_type_one],\n",
    "                                      c=\"red\", marker=\"o\", label=iris.target_names[0])\n",
    "scatter_1 = matplotlib.pyplot.scatter(x1[start_type_one:start_type_two], x2[start_type_one:start_type_two],\n",
    "                                      c=\"blue\", marker=\"^\", label=iris.target_names[1])\n",
    "scatter_2 = matplotlib.pyplot.scatter(x1[start_type_two:], x2[start_type_two:],\n",
    "                                      c=\"green\", marker=\"*\", label=iris.target_names[2])\n",
    "\n",
    "# add a legend to explain which points are which\n",
    "matplotlib.pyplot.legend(handles=[scatter_0, scatter_1, scatter_2])\n",
    "\n",
    "# show the graph\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Next, we want to fit our decision tree model to the iris data we're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Model Output\n",
    "\n",
    "Using graphviz and pydot, we can create a flowchart that shows the model decisions. The flowchart will be printed to a PDF on your desktop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "tree.export_graphviz(model, out_file=dot_data, feature_names=iris.feature_names, class_names=iris.target_names,\n",
    "                     filled=True, rounded=True, special_characters=True)\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())[0]\n",
    "# graph.write_pdf(os.path.expanduser(\"~/Downloads/ML/iris_decision_tree_flowchart_test.pdf\"))\n",
    "# commented out becasue I don't want to get a new flowchart each time I run the program (the flowchart changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Now we can make some predictions using the trained model. We'll pull out some examples from our training data and see what the model says about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions: [0 1 2]\n",
      "Probabilities:\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Use the first input from each class\n",
    "inputs = [iris.data[0], iris.data[start_type_one], iris.data[start_type_two]]\n",
    "\n",
    "print('Class predictions: {0}'.format(model.predict(inputs))) # guess which class\n",
    "print('Probabilities:\\n{0}'.format(model.predict_proba(inputs))) # give probability of each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Option #1 - Standard Difficulty\n",
    "\n",
    "Answer the following questions. You may find it helpful to compare the PDF output to the graph above (remember you can change which columns the graph is displaying), to see the boundaries the decision tree is finding.\n",
    "\n",
    "0. Submit the PDF you generated as a separate file in Canvas.\n",
    "1. According to the PDF, what feature values would tell you with high probability that you were looking at a setosa iris?\n",
    "1. According to the PDF, which features would you look at to tell a virginica from a versicolor?\n",
    "1. What is the value array in the PDF showing?\n",
    "1. The predictions just above are all 100% confident in the correct answer. If you try using other data points from the training data, you'll find the same thing. Why is that always true for our Decision Tree?\n",
    "1. Try using subsets of the input data (look at the iris_inputs variable in [LogisticRegressionIris](https://nbviewer.jupyter.org/github/jennselby/MachineLearningCourseNotes/blob/master/assets/ipynb/LogisticRegressionIris.ipynb) to see how to use only some of the columns in the model). How does this change the decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers for Option \\#1\n",
    "_The pdf changes each time I export it, so these answers are based on the pdf which is in the git repo provided below._\n",
    "\n",
    "**0.**  \n",
    "`iris_decision_tree_flowchart_original.pdf` is in [this](https://github.com/pauburk/intro-to-ml) git repo along with all of my other stuff.\n",
    "\n",
    "**1.**  \n",
    "If the petal width is less than or equal to 0.8 cm.\n",
    "\n",
    "**2.**  \n",
    "The petal width is also the biggest factor in determining between virginica and versicolor, 49 out of 54 samples with petal width <= 1.75 cm are versicolor and 45 out of 46 samples with petal width > 1.75 cm are virginica. The petal length is the next biggest factor, and then either the petal width again or the sepal length.\n",
    "\n",
    "**3.**  \n",
    "The value array looks like `value=[a, b, c]` where a is the number of setosa flowers left at that place in the decision tree, b represents versicolor, and c is virginica. For example, at the first fork in the tree, the leaf on the left branch has `value=[50, 0, 0]`, which means that whatever the decision was, it seperated 50 setosas without taking anything else.\n",
    "\n",
    "**4.**\n",
    "Because if you plug in a data point from the training data, the model will already know the type of iris because the answer for that data point was provided in training (`iris.target`).\n",
    "\n",
    "**5.**  \n",
    "In the example below, the decision tree no longer can use sepal length and width to help seperate the flowers (only petal length and width). This could either add or subtract branches/time to the decision tree.\n",
    "\n",
    "Here's a hypothetical example. What if sepal length was really good for telling versicolor and virginica apart? But if the decision tree could no longer use sepal length to distinguish flowers, it has to use petal length and width instead, which adds a couple branches because versicolor and virginica have similar petal lengths and widths.\n",
    "\n",
    "The pdf generated below is `iris_decision_tree_flowchart_new.pdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new model using only petal length and petal width\n",
    "\n",
    "m = tree.DecisionTreeClassifier()\n",
    "m.fit(iris.data[:,[2 ,3]], iris.target)\n",
    "\n",
    "# export the flowchart\n",
    "\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(m, out_file=dot_data, feature_names=iris.feature_names[2:4], class_names=iris.target_names,\n",
    "                     filled=True, rounded=True, special_characters=True)\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())[0]\n",
    "# graph.write_pdf(os.path.expanduser(\"~/Downloads/ML/iris_decision_tree_flowchart_new.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Option #2 - Advanced Difficulty\n",
    "\n",
    "Try fitting a Random Forest model to the iris data. See [this example](http://scikit-learn.org/stable/modules/ensemble.html#forest) to help you get started.\n",
    "\n",
    "How does the performance and output of Random Forest compare to the single Decision Tree? Since you can't get the graphical representation of the Random Forest model the way we did for the single Decision Tree, you'll have to think of a different way to understand what the model is doing. Think about how we can [validate the performance of our classifier models](https://jennselby.github.io/MachineLearningCourseNotes/#classification-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# for metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# split the data into training and testing groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "RF_pred = regressor.predict(data_test)\n",
    "\n",
    "# round predictions to int in order to calculate metrics\n",
    "for i in range(len(RF_pred)):\n",
    "    RF_pred[i] = int(RF_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for [setosa, versicolor, virginica]: [1.     0.8125 1.    ]\n",
      "avg precision (calculated using average='micro'): 0.9\n",
      "\n",
      "recall for [setosa, versicolor, virginica]: [1.  1.  0.5]\n",
      "avg recall (calculated using average='micro'): 0.9\n",
      "\n",
      "f1 score for [setosa, versicolor, virginica]: [1.         0.89655172 0.66666667]\n",
      "avg f1 score (calculated using average='micro'): 0.9\n",
      "\n",
      "accuracy score: 0.9\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics for random forest\n",
    "\n",
    "# precision\n",
    "\n",
    "RF_p = precision_score(y_test, RF_pred, average=None)\n",
    "print(\"precision for [setosa, versicolor, virginica]:\", RF_p)\n",
    "\n",
    "RF_p_avg = precision_score(y_test, RF_pred, average=\"micro\")\n",
    "print(\"avg precision (calculated using average=\\'micro\\'):\", RF_p_avg)\n",
    "\n",
    "# recall\n",
    "\n",
    "RF_r = recall_score(y_test, RF_pred, average=None)\n",
    "print(\"\\nrecall for [setosa, versicolor, virginica]:\", RF_r)\n",
    "\n",
    "RF_r_avg = recall_score(y_test, RF_pred, average=\"micro\")\n",
    "print(\"avg recall (calculated using average=\\'micro\\'):\", RF_r_avg)\n",
    "\n",
    "# f1 score\n",
    "\n",
    "RF_f1 = f1_score(y_test, RF_pred, average=None)\n",
    "print(\"\\nf1 score for [setosa, versicolor, virginica]:\", RF_f1)\n",
    "\n",
    "RF_f1_avg = f1_score(y_test, RF_pred, average=\"micro\")\n",
    "print(\"avg f1 score (calculated using average=\\'micro\\'):\", RF_f1_avg)\n",
    "\n",
    "# accuracy\n",
    "\n",
    "RF_acc = accuracy_score(y_test, RF_pred)\n",
    "print(\"\\naccuracy score:\", RF_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a new decision tree model with the split data\n",
    "\n",
    "new_model = tree.DecisionTreeClassifier()\n",
    "new_model.fit(X_train, y_train)\n",
    "\n",
    "DT_pred = new_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for [setosa, versicolor, virginica]: [1. 1. 1.]\n",
      "avg precision (calculated using average='micro'): 1.0\n",
      "\n",
      "recall for [setosa, versicolor, virginica]: [1. 1. 1.]\n",
      "avg recall (calculated using average='micro'): 1.0\n",
      "\n",
      "f1 score for [setosa, versicolor, virginica]: [1. 1. 1.]\n",
      "avg f1 score (calculated using average='micro'): 1.0\n",
      "\n",
      "accuracy score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics for random forest\n",
    "\n",
    "# precision\n",
    "\n",
    "RF_p = precision_score(y_test, DT_pred, average=None)\n",
    "print(\"precision for [setosa, versicolor, virginica]:\", RF_p)\n",
    "\n",
    "RF_p_avg = precision_score(y_test, DT_pred, average=\"micro\")\n",
    "print(\"avg precision (calculated using average=\\'micro\\'):\", RF_p_avg)\n",
    "\n",
    "# recall\n",
    "\n",
    "RF_r = recall_score(y_test, DT_pred, average=None)\n",
    "print(\"\\nrecall for [setosa, versicolor, virginica]:\", RF_r)\n",
    "\n",
    "RF_r_avg = recall_score(y_test, DT_pred, average=\"micro\")\n",
    "print(\"avg recall (calculated using average=\\'micro\\'):\", RF_r_avg)\n",
    "\n",
    "# f1 score\n",
    "\n",
    "RF_f1 = f1_score(y_test, DT_pred, average=None)\n",
    "print(\"\\nf1 score for [setosa, versicolor, virginica]:\", RF_f1)\n",
    "\n",
    "RF_f1_avg = f1_score(y_test, DT_pred, average=\"micro\")\n",
    "print(\"avg f1 score (calculated using average=\\'micro\\'):\", RF_f1_avg)\n",
    "\n",
    "# accuracy\n",
    "\n",
    "RF_acc = accuracy_score(y_test, DT_pred)\n",
    "print(\"\\naccuracy score:\", RF_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest vs. decision tree\n",
    "\n",
    "So in this case it turns out that the decision tree model performs better than the random forest model. Why this is?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
